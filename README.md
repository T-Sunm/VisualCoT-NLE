# VisualCoT for ViQVQA (See‚ÄìThink‚ÄìConfirm)

## üöÄ Quick Setup (One-time Installation)

This guide assumes you are working in the `~/workspace/VisualCoT-NLE` directory.

### 1. Activate Environment
```bash
source /home/research/my_envs/vllm_env/bin/activate
```
*Your prompt should change to `(vllm_env)`.*

### 2. Install vLLM
```bash
uv pip install vllm --torch-backend=auto
```

### 3. Install Dependencies

**VisualCoT-NLE Dependencies:**
```bash
uv add -r requirements.txt
```

**Describe-Anything (DAM) - External:**
```bash
cd external/describe-anything
pip install -v .
cd ../..
```

---

## üõ†Ô∏è Usage Guide (Runtime)

‚ö†Ô∏è **Quan tr·ªçng**: C·∫ßn m·ªü **3 terminal ri√™ng bi·ªát** ƒë·ªÉ ch·∫°y c√°c server v√† pipeline.

---

### Terminal 1: Start vLLM Server (LLM API)

```bash
# Activate m√¥i tr∆∞·ªùng vLLM
source /home/research/my_envs/vllm_env/bin/activate

# Start vLLM v·ªõi Vintern-1B (cho ti·∫øng Vi·ªát)
vllm serve 5CD-AI/Vintern-1B-v3_5 \
    --port 1234 \
    --dtype auto \
    --gpu-memory-utilization 0.5 \
    --max-model-len 2048 \
    --trust-remote-code
```
> Server s·∫Ω ch·∫°y t·∫°i `http://localhost:1234`

---

### Terminal 2: Start DAM Server (Describe-Anything Model)

```bash
# Activate m√¥i tr∆∞·ªùng vLLM (ho·∫∑c m√¥i tr∆∞·ªùng ri√™ng n·∫øu c√≥)
source /home/research/my_envs/vllm_env/bin/activate

# Di chuy·ªÉn v√†o th∆∞ m·ª•c DAM
cd ~/workspace/VisualCoT-NLE/external/describe-anything

# Start DAM server
python dam_server.py \
    --model-path nvidia/DAM-3B \
    --conv-mode v1 \
    --prompt-mode focal_prompt \
    --port 8000
```
> Server s·∫Ω ch·∫°y t·∫°i `http://localhost:8000`

---

### Terminal 3: Run ViQVQA Pipeline

```bash
# Activate m√¥i tr∆∞·ªùng ch√≠nh c·ªßa project
source /home/research/my_envs/vllm_env/bin/activate

# Di chuy·ªÉn v√†o th∆∞ m·ª•c project
cd ~/workspace/VisualCoT-NLE

# Ch·∫°y pipeline
python src/pipeline.py \
    --config configs/experiments/vivqax_baseline.yaml \
    --limit 300 \
    --output results/vivqax_results.json
```

---

## üìä Ki·ªÉm tra k·∫øt qu·∫£

Sau khi ch·∫°y xong, k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u t·∫°i:
```
results/vivqax_results.json
```

---

## üìÇ Data Preparation

ƒê·∫£m b·∫£o c·∫•u tr√∫c d·ªØ li·ªáu sau:
- **Images**: COCO images (`data/raw/coco/images/val2014`)
- **Annotations**: ViVQA-X annotations (`data/raw/vivqa-x/annotations/test.json`)
- **Scene Graphs**: Pre-computed scene graphs t·∫°i `data/raw/scene-graph/`

---

## üìÑ Citation
[Visual Chain-of-Thought Prompting for Knowledge-based Visual Reasoning](https://arxiv.org/abs/2301.05226)
```bibtex
@article{chen2023see,
  title={Visual Chain-of-Thought Prompting for Knowledge-based Visual Reasoning},
  author={Chen, Zhenfang and Zhou, Qinhong and Shen, Yikang and Hong, Yining and Sun, Zhiqing and Gutfreund, Dan and Gan, Chuang},
  journal={arXiv preprint arXiv:2301.05226},
  year={2023}
}
```