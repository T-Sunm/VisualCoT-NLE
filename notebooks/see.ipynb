{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bff52b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: e:\\AIO\\Project\\VisualCoT\n",
      "Src path: e:\\AIO\\Project\\VisualCoT\\src\n",
      "Src exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Asus\\App\\miniconda\\workspace\\envs\\vctp-nle\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 1: Load annotations ===\n",
      "Loaded 10 questions\n",
      "Sample keys: ['0<->22MexNkBPpdZGX6sxbxVBH', '1<->22ZAvqke8EhGDj8e4eyios', '2<->22oou4R5ejh4Ay9UQG7yGT']\n",
      "\n",
      "=== STEP 2: Check scene graph files ===\n",
      "SG dir exists: True\n",
      "SG attr dir exists: True\n",
      "Found 1 scene graph files\n",
      "Sample files: ['000000000000.json']\n",
      "\n",
      "=== STEP 3: Test with first sample ===\n",
      "Looking for scene graph: e:\\AIO\\Project\\VisualCoT\\data\\processed\\input_text\\scene_graph_text\\scene_graph_coco17\\000000000000.json\n",
      "Exists: True\n",
      "\n",
      "=== STEP 4: Build similarity (if scene graphs exist) ===\n",
      "[CLIPManager] Loading CLIP with tokenizer: openai/clip-vit-base-patch16 on cpu\n",
      "[CLIPManager] ✓ Model cached: openai/clip-vit-base-patch16_tokenizer_cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved similarity scores to e:\\AIO\\Project\\VisualCoT\\data\\processed\\object_similarity\\train_object_select_aokvqa_answer.pkl\n",
      "\n",
      "✓ Built similarity dict with 1 keys\n",
      "✓ Saved to e:\\AIO\\Project\\VisualCoT\\data\\processed\\object_similarity\\train_object_select_aokvqa_answer.pkl\n",
      "✓ Verification: Loaded 1 keys from PKL file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build_similarity_test.py\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Fix the path to load modules correctly from notebook\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent  # Go up one level from notebooks/ to project root\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "# Add src to path if not already there\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Src path: {src_path}\")\n",
    "print(f\"Src exists: {src_path.exists()}\")\n",
    "\n",
    "from vctp.data.preprocess.object_similarity.similarity_builder import ObjectSimilarityBuilder\n",
    "from vctp.data.preprocess.object_similarity.metrics import AnswerSimilarityMetric\n",
    "from vctp.data.preprocess.object_similarity.aokvqa_processor import AOKVQASimilarityProcessor\n",
    "\n",
    "# Paths (relative to project root)\n",
    "annotations_dir = project_root / \"data/raw/aokvqa_annotations\"\n",
    "sg_path = project_root / \"data/processed/input_text/scene_graph_text\"\n",
    "output_path = project_root / \"data/processed/object_similarity/train_object_select_aokvqa_answer.pkl\"\n",
    "\n",
    "print(\"\\n=== STEP 1: Load annotations ===\")\n",
    "processor = AOKVQASimilarityProcessor(str(annotations_dir))\n",
    "questions, answers, rationales = processor.load_split(\"train\")\n",
    "\n",
    "print(f\"Loaded {len(questions)} questions\")\n",
    "print(f\"Sample keys: {list(questions.keys())[:3]}\")\n",
    "\n",
    "print(\"\\n=== STEP 2: Check scene graph files ===\")\n",
    "sg_dir = sg_path / \"scene_graph_coco17\"\n",
    "sg_attr_dir = sg_path / \"scene_graph_coco17_attr\"\n",
    "\n",
    "print(f\"SG dir exists: {sg_dir.exists()}\")\n",
    "print(f\"SG attr dir exists: {sg_attr_dir.exists()}\")\n",
    "\n",
    "if sg_dir.exists():\n",
    "    sg_files = list(sg_dir.glob(\"*.json\"))\n",
    "    print(f\"Found {len(sg_files)} scene graph files\")\n",
    "    if sg_files:\n",
    "        print(f\"Sample files: {[f.name for f in sg_files[:3]]}\")\n",
    "else:\n",
    "    print(\"❌ Scene graph directory NOT FOUND!\")\n",
    "    print(\"This is why the PKL file is empty - no scene graphs to process!\")\n",
    "    raise FileNotFoundError(f\"Scene graph directory not found: {sg_dir}\")\n",
    "\n",
    "print(\"\\n=== STEP 3: Test with first sample ===\")\n",
    "# Get first key\n",
    "first_key = list(questions.keys())[0]\n",
    "img_id = int(first_key.split(\"<->\")[0])\n",
    "\n",
    "sg_file = sg_dir / f\"{str(img_id).zfill(12)}.json\"\n",
    "print(f\"Looking for scene graph: {sg_file}\")\n",
    "print(f\"Exists: {sg_file.exists()}\")\n",
    "\n",
    "if not sg_file.exists():\n",
    "    print(f\"\\n❌ Scene graph for image {img_id} NOT FOUND!\")\n",
    "    print(f\"This is the problem - your test sample images don't have scene graphs!\")\n",
    "    print(f\"\\nYou need to either:\")\n",
    "    print(f\"1. Generate scene graphs for your test images (0-9)\")\n",
    "    print(f\"2. Use a different set of training images that have scene graphs\")\n",
    "    raise FileNotFoundError(f\"Scene graph not found: {sg_file}\")\n",
    "\n",
    "print(\"\\n=== STEP 4: Build similarity (if scene graphs exist) ===\")\n",
    "metric = AnswerSimilarityMetric()\n",
    "builder = ObjectSimilarityBuilder(\n",
    "    sg_dir=sg_dir,\n",
    "    sg_attr_dir=sg_attr_dir,\n",
    "    metric=metric,\n",
    ")\n",
    "\n",
    "similarity_dict = builder.build(\n",
    "    questions=questions,\n",
    "    answers=answers,\n",
    "    rationales=rationales,\n",
    "    output_path=str(output_path),\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Built similarity dict with {len(similarity_dict)} keys\")\n",
    "print(f\"✓ Saved to {output_path}\")\n",
    "\n",
    "# Verify\n",
    "with open(output_path, \"rb\") as f:\n",
    "    loaded = pickle.load(f)\n",
    "print(f\"✓ Verification: Loaded {len(loaded)} keys from PKL file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8862de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PKL FILE CONTENT ===\n",
      "Number of keys: 1\n",
      "\n",
      "Keys in PKL:\n",
      "  - 0<->22MexNkBPpdZGX6sxbxVBH\n",
      "\n",
      "=== First Entry Details ===\n",
      "Key: 0<->22MexNkBPpdZGX6sxbxVBH\n",
      "Value type: <class 'dict'>\n",
      "Value: {'arm': 0.5491220951080322, 'face': 0.6824137568473816, 'hair': 0.652134120464325, 'hand': 0.5920497179031372, 'handle': 0.6108238697052002, 'head': 0.5802187323570251, 'leg': 0.5364360213279724, 'man': 0.651434063911438, 'person': 0.649359941482544, 'player': 0.7496165037155151, 'racket': 0.6210474967956543, 'shirt': 0.6177270412445068, 'shoe': 0.6860548257827759, 'short': 0.6840023994445801, 'sneaker': 0.6612303256988525, 'sock': 0.6086715459823608, 'shadow': 0.6272501945495605, 'ball': 0.6987450122833252, 'line': 0.5646349787712097, 'court': 0.6837835311889648, 'knee': 0.5892088413238525, 'watch': 0.6974292993545532, 'ground': 0.6758285164833069, 'mouth': 0.6402465105056763, 'wrist': 0.5146611332893372, 'writing': 0.6421564817428589, 'tennis ball': 0.5933190584182739, 'tennis racket': 0.5826085209846497}\n",
      "\n",
      "Value has 28 objects:\n",
      "  arm: 0.5491\n",
      "  face: 0.6824\n",
      "  hair: 0.6521\n",
      "  hand: 0.5920\n",
      "  handle: 0.6108\n"
     ]
    }
   ],
   "source": [
    "# Verify the PKL content\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "pkl_path = project_root / \"data/processed/object_similarity/train_object_select_aokvqa_answer.pkl\"\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    pkl_data = pickle.load(f)\n",
    "\n",
    "print(f\"=== PKL FILE CONTENT ===\")\n",
    "print(f\"Number of keys: {len(pkl_data)}\")\n",
    "print(f\"\\nKeys in PKL:\")\n",
    "for key in pkl_data.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "# Show first entry details\n",
    "if pkl_data:\n",
    "    first_key = list(pkl_data.keys())[0]\n",
    "    print(f\"\\n=== First Entry Details ===\")\n",
    "    print(f\"Key: {first_key}\")\n",
    "    print(f\"Value type: {type(pkl_data[first_key])}\")\n",
    "    print(f\"Value: {pkl_data[first_key]}\")\n",
    "    \n",
    "    # If it's a dict, show its structure\n",
    "    if isinstance(pkl_data[first_key], dict):\n",
    "        print(f\"\\nValue has {len(pkl_data[first_key])} objects:\")\n",
    "        for obj_name, score in list(pkl_data[first_key].items())[:5]:\n",
    "            print(f\"  {obj_name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL SAMPLE ===\n",
      "Image ID: 0\n",
      "Question ID: 22MexNkBPpdZGX6sxbxVBH\n",
      "Question: What is the man by the bags awaiting?\n",
      "Choices: ['skateboarder', 'train', 'delivery', 'cab']\n",
      "Correct choice: 3\n",
      "Direct answers: ['ride', 'ride', 'bus', 'taxi', 'travelling', 'traffic', 'taxi', 'cab', 'cab', 'his ride']\n",
      "\n",
      "=== ANSWER ===\n",
      "Answer: cab\n",
      "\n",
      "=== OBJECT SIMILARITY TO ANSWER 'cab' ===\n",
      "\n",
      "Top 10 most relevant objects:\n",
      "  1. player: 0.7496\n",
      "  2. ball: 0.6987\n",
      "  3. watch: 0.6974\n",
      "  4. shoe: 0.6861\n",
      "  5. short: 0.6840\n",
      "  6. court: 0.6838\n",
      "  7. face: 0.6824\n",
      "  8. ground: 0.6758\n",
      "  9. sneaker: 0.6612\n",
      "  10. hair: 0.6521\n",
      "\n",
      "Bottom 5 least relevant objects:\n",
      "  head: 0.5802\n",
      "  line: 0.5646\n",
      "  arm: 0.5491\n",
      "  leg: 0.5364\n",
      "  wrist: 0.5147\n"
     ]
    }
   ],
   "source": [
    "# Compare with original implementation\n",
    "import json\n",
    "\n",
    "# Load the annotation to see the actual question/answer\n",
    "with open(project_root / \"data/raw/aokvqa_annotations/aokvqa_v1p0_train_from_hf.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Find the sample with image_id=0\n",
    "sample = train_data[0]\n",
    "print(\"=== ORIGINAL SAMPLE ===\")\n",
    "print(f\"Image ID: {sample['image_id']}\")\n",
    "print(f\"Question ID: {sample['question_id']}\")\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Choices: {sample['choices']}\")\n",
    "print(f\"Correct choice: {sample['correct_choice_idx']}\")\n",
    "print(f\"Direct answers: {sample['direct_answers']}\")\n",
    "\n",
    "# Get the answer\n",
    "answer = sample['choices'][sample['correct_choice_idx']]\n",
    "print(f\"\\n=== ANSWER ===\")\n",
    "print(f\"Answer: {answer}\")\n",
    "\n",
    "# Now check the PKL scores\n",
    "print(f\"\\n=== OBJECT SIMILARITY TO ANSWER '{answer}' ===\")\n",
    "obj_scores = pkl_data['0<->22MexNkBPpdZGX6sxbxVBH']\n",
    "sorted_objs = sorted(obj_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 10 most relevant objects:\")\n",
    "for i, (obj_name, score) in enumerate(sorted_objs[:10], 1):\n",
    "    print(f\"  {i}. {obj_name}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nBottom 5 least relevant objects:\")\n",
    "for obj_name, score in sorted_objs[-5:]:\n",
    "    print(f\"  {obj_name}: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbfa70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST OBJECT SIMILARITY RETRIEVAL ===\n",
      "✓ Loaded 1 entries from PKL\n",
      "\n",
      "✓ Retrieved top 10 objects for '0<->22MexNkBPpdZGX6sxbxVBH':\n",
      "  1. player: 0.7496\n",
      "  2. ball: 0.6987\n",
      "  3. watch: 0.6974\n",
      "  4. shoe: 0.6861\n",
      "  5. short: 0.6840\n",
      "  6. court: 0.6838\n",
      "  7. face: 0.6824\n",
      "  8. ground: 0.6758\n",
      "  9. sneaker: 0.6612\n",
      "  10. hair: 0.6521\n",
      "\n",
      "✓ PKL file works correctly for retrieval!\n"
     ]
    }
   ],
   "source": [
    "# Test loading and using the PKL file directly\n",
    "import pickle\n",
    "from typing import List\n",
    "print(\"\\n=== TEST OBJECT SIMILARITY RETRIEVAL ===\")\n",
    "\n",
    "# Load PKL\n",
    "pkl_path = project_root / \"data/processed/object_similarity/train_object_select_aokvqa_answer.pkl\"\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    object_similarity_dict = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(object_similarity_dict)} entries from PKL\")\n",
    "\n",
    "# Function to get top K objects for a question\n",
    "def get_top_objects(question_key: str, top_k: int = 10) -> List[str]:\n",
    "    \"\"\"Get top K most relevant objects for a question.\"\"\"\n",
    "    if question_key not in object_similarity_dict:\n",
    "        return []\n",
    "    \n",
    "    obj_scores = object_similarity_dict[question_key]\n",
    "    # Sort by score descending\n",
    "    sorted_objs = sorted(obj_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Return top K object names\n",
    "    return [obj_name for obj_name, score in sorted_objs[:top_k]]\n",
    "\n",
    "# Test with first sample\n",
    "test_key = '0<->22MexNkBPpdZGX6sxbxVBH'\n",
    "top_objects = get_top_objects(test_key, top_k=10)\n",
    "\n",
    "print(f\"\\n✓ Retrieved top 10 objects for '{test_key}':\")\n",
    "for i, obj_name in enumerate(top_objects, 1):\n",
    "    score = object_similarity_dict[test_key][obj_name]\n",
    "    print(f\"  {i}. {obj_name}: {score:.4f}\")\n",
    "\n",
    "print(\"\\n✓ PKL file works correctly for retrieval!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb7a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: e:\\AIO\\Project\\VisualCoT\\notebooks\n",
      "Project root: e:\\AIO\\Project\\VisualCoT\n",
      "PKL path: e:\\AIO\\Project\\VisualCoT\\data\\processed\\object_similarity\\train_object_select_aokvqa_answer.pkl\n",
      "PKL exists: True\n",
      "\n",
      "Existing PKL has 1 keys\n",
      "Sample 0 has 28 objects\n",
      "\n",
      "✓ Created dummy PKL with 10 samples\n",
      "✓ Saved to e:\\AIO\\Project\\VisualCoT\\data\\processed\\object_similarity\\train_object_select_aokvqa_answer.pkl\n",
      "\n",
      "=== VERIFICATION ===\n",
      "Loaded PKL has 10 keys\n",
      "Keys:\n",
      "  1. 0<->22MexNkBPpdZGX6sxbxVBH\n",
      "  2. 1<->22ZAvqke8EhGDj8e4eyios\n",
      "  3. 2<->22oou4R5ejh4Ay9UQG7yGT\n",
      "  4. 3<->22qCSTGL82TcgGtu9wtcrL\n",
      "  5. 4<->22qvnfBREuA4LUGw3cfTgg\n",
      "  6. 5<->23NaDk4gncPVsGzZ7UuxNK\n",
      "  7. 6<->23VQ24vGdCfx2vuwoNqxwk\n",
      "  8. 7<->23ibLk5tF4wVKd7MMms9Yp\n",
      "  9. 8<->23x4iQXWfAeZxqCJVbTuv5\n",
      "  10. 9<->23xWxgFhSv5sZaxwJrqJwm\n",
      "\n",
      "All samples have 28 objects\n"
     ]
    }
   ],
   "source": [
    "# Fix đường dẫn trong notebook\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# ĐÚNG: Get project root (lên 1 cấp từ notebooks/)\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent  # Go up from notebooks/ to project root\n",
    "\n",
    "print(f\"Notebook dir: {notebook_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Đường dẫn đến PKL file\n",
    "pkl_path = project_root / \"data/processed/object_similarity/train_object_select_aokvqa_answer.pkl\"\n",
    "print(f\"PKL path: {pkl_path}\")\n",
    "print(f\"PKL exists: {pkl_path.exists()}\")\n",
    "\n",
    "# Load existing\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    existing = pickle.load(f)\n",
    "\n",
    "print(f\"\\nExisting PKL has {len(existing)} keys\")\n",
    "\n",
    "# Get sample 0 data\n",
    "sample_0_objects = existing[\"0<->22MexNkBPpdZGX6sxbxVBH\"]\n",
    "print(f\"Sample 0 has {len(sample_0_objects)} objects\")\n",
    "\n",
    "# All 10 keys\n",
    "keys = [\n",
    "    \"0<->22MexNkBPpdZGX6sxbxVBH\",\n",
    "    \"1<->22ZAvqke8EhGDj8e4eyios\", \n",
    "    \"2<->22oou4R5ejh4Ay9UQG7yGT\",\n",
    "    \"3<->22qCSTGL82TcgGtu9wtcrL\",\n",
    "    \"4<->22qvnfBREuA4LUGw3cfTgg\",\n",
    "    \"5<->23NaDk4gncPVsGzZ7UuxNK\",\n",
    "    \"6<->23VQ24vGdCfx2vuwoNqxwk\",\n",
    "    \"7<->23ibLk5tF4wVKd7MMms9Yp\",\n",
    "    \"8<->23x4iQXWfAeZxqCJVbTuv5\",\n",
    "    \"9<->23xWxgFhSv5sZaxwJrqJwm\",\n",
    "]\n",
    "\n",
    "# Create dummy with all samples using sample 0's data\n",
    "dummy = {key: sample_0_objects.copy() for key in keys}\n",
    "\n",
    "# Save\n",
    "with open(pkl_path, \"wb\") as f:\n",
    "    pickle.dump(dummy, f)\n",
    "\n",
    "print(f\"\\n✓ Created dummy PKL with {len(dummy)} samples\")\n",
    "print(f\"✓ Saved to {pkl_path}\")\n",
    "\n",
    "# Verify\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    loaded = pickle.load(f)\n",
    "    \n",
    "print(f\"\\n=== VERIFICATION ===\")\n",
    "print(f\"Loaded PKL has {len(loaded)} keys\")\n",
    "print(f\"Keys:\")\n",
    "for i, key in enumerate(loaded.keys(), 1):\n",
    "    print(f\"  {i}. {key}\")\n",
    "print(f\"\\nAll samples have {len(loaded[keys[0]])} objects\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vctp-nle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
